{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6U6rApkKqAzM"
      },
      "outputs": [],
      "source": [
        "# final project code\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 常數與基本設定\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Poincaré best constant for (0,1)^3 with mean-zero condition: C_P = 1/pi\n",
        "C_poincare = 1.0 / torch.pi\n",
        "\n",
        "# Sobolev best constant in R^3: C_S = 4^{1/3} / pi^{11/12}\n",
        "C_sobolev = (4.0 ** (1.0 / 3.0)) / (torch.pi ** (11.0 / 12.0))\n",
        "\n",
        "# 取樣點數\n",
        "N_samples = 4096"
      ],
      "metadata": {
        "id": "HPORJPIPqcbZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "這裡我們考慮兩個不同的constrain在domain $\\Omega=(0,1)^{3}$。一個是 Poincare inequality for p=2，另一個是 Sobolev inequality:\n",
        "\\begin{align}\\tag{1}\n",
        "  \\Vert u\\Vert_{2,\\Omega}\\leq\\frac{1}{\\pi}\\Vert\\nabla u\\Vert_{2,\\Omega},\\qquad \\text{with}\\quad \\frac{1}{\\vert\\Omega\\vert}\\int_{\\Omega}u(x)\\,dx,\n",
        "\\end{align}\n",
        "and\n",
        "\\begin{align}\\tag{2}\n",
        "  \\Vert u\\Vert_{6,\\Omega}\\leq\\frac{4^{\\frac{1}{3}}}{\\pi^{\\frac{11}{12}}}\\Vert\\nabla u\\Vert_{2,\\Omega}.\n",
        "\\end{align}"
      ],
      "metadata": {
        "id": "ywt7Nq8eqxGa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. 定義網路 u_theta(x)\n",
        "#    - input dimension: 3 (x1, x2, x3)\n",
        "#    - hidden layers: 3 層, 每層寬度 64, sigmoid activation\n",
        "#    - output dimension: 1\n",
        "class SigmoidNet3D(nn.Module):\n",
        "    def __init__(self, in_dim=3, hidden_dim=64, num_hidden_layers=3, out_dim=1):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        # input layer\n",
        "        layers.append(nn.Linear(in_dim, hidden_dim))\n",
        "        layers.append(nn.Sigmoid())\n",
        "        # hidden layers\n",
        "        for _ in range(num_hidden_layers - 1):\n",
        "            layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
        "            layers.append(nn.Sigmoid())\n",
        "        # output layer\n",
        "        layers.append(nn.Linear(hidden_dim, out_dim))\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (N, 3)\n",
        "        return self.net(x)  # (N, 1)\n",
        "\n",
        "model = SigmoidNet3D().to(device)"
      ],
      "metadata": {
        "id": "fcrZ2naasUpK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. 取樣 (0,1)^3 上的點，近似積分\n",
        "def sample_points_on_cube(n_samples):\n",
        "    \"\"\"\n",
        "    Uniformly sample n_samples points in Omega = (0,1)^3.\n",
        "    \"\"\"\n",
        "    # shape: (n_samples, 3)\n",
        "    x = torch.rand(n_samples, 3, device=device, requires_grad=True)\n",
        "    return x"
      ],
      "metadata": {
        "id": "3jGO1HCjspw4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. 計算約束相關的 norm 與 loss\n",
        "def constraint_loss(model, n_samples=N_samples):\n",
        "    # 取樣點\n",
        "    x = sample_points_on_cube(n_samples)  # (N, 3), requires_grad=True\n",
        "\n",
        "    # u_theta(x)\n",
        "    u = model(x)  # (N, 1)\n",
        "    u = u.squeeze(-1)  # 變成 (N,)\n",
        "\n",
        "    # 1) 平均值條件: (1/|Omega|) ∫ u = 0\n",
        "    # 對 (0,1)^3, |Omega| = 1, 所以 integral ≈ mean\n",
        "    mean_u = u.mean()\n",
        "    mean_zero_penalty = mean_u ** 2   # 想要 mean_u -> 0\n",
        "\n",
        "    # 2) 計算 gradient ∇u (用 autograd)\n",
        "    grad_u = torch.autograd.grad(\n",
        "        outputs=u,\n",
        "        inputs=x,\n",
        "        grad_outputs=torch.ones_like(u),\n",
        "        create_graph=True,\n",
        "        retain_graph=True,\n",
        "        only_inputs=True\n",
        "    )[0]  # shape: (N, 3)\n",
        "\n",
        "    # L2 norm of u over Omega (approx via Monte Carlo)\n",
        "    # \\|u\\|_{2,\\Omega} ≈ (∫ |u|^2)^{1/2} ≈ (mean(|u|^2))^{1/2}\n",
        "    L2_u = torch.sqrt((u ** 2).mean() + 1e-12)\n",
        "\n",
        "    # L6 norm of u over Omega\n",
        "    # \\|u\\|_{6,\\Omega} ≈ (mean(|u|^6))^{1/6}\n",
        "    L6_u = ((u.abs() ** 6).mean() + 1e-12) ** (1.0 / 6.0)\n",
        "\n",
        "    # L2 norm of gradient\n",
        "    # \\|\\nabla u\\|_{2,\\Omega} ≈ (mean(|∇u|^2))^{1/2}\n",
        "    grad_sq = (grad_u ** 2).sum(dim=1)  # (N,), each is |∇u(x)|^2\n",
        "    L2_grad = torch.sqrt(grad_sq.mean() + 1e-12)\n",
        "\n",
        "    # 3) Poincaré constraint: ||u||_2 <= (1/pi) ||∇u||_2\n",
        "    # 用 ReLU 懲罰違反的部分: max(0, ||u||_2 - C_poincare * ||∇u||_2)\n",
        "    poincare_violation = torch.relu(L2_u - C_poincare * L2_grad)\n",
        "    poincare_penalty = poincare_violation ** 2\n",
        "\n",
        "    # 4) Sobolev constraint: ||u||_6 <= C_sobolev * ||∇u||_2\n",
        "    sobolev_violation = torch.relu(L6_u - C_sobolev * L2_grad)\n",
        "    sobolev_penalty = sobolev_violation ** 2\n",
        "\n",
        "    # constraint loss\n",
        "    total_constraint_loss = mean_zero_penalty + poincare_penalty + sobolev_penalty\n",
        "\n",
        "    # total_loss = task_loss + alpha * total_constraint_loss\n",
        "    return total_constraint_loss, {\n",
        "        \"mean_u\": mean_u.item(),\n",
        "        \"L2_u\": L2_u.item(),\n",
        "        \"L6_u\": L6_u.item(),\n",
        "        \"L2_grad\": L2_grad.item(),\n",
        "        \"poincare_violation\": poincare_violation.item(),\n",
        "        \"sobolev_violation\": sobolev_violation.item(),\n",
        "    }\n"
      ],
      "metadata": {
        "id": "2TATuiLssvCY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note** 理論上的不等式應該是要完全滿足，不過我們採用soft constraint。另外，為了讓違反越來越小，我們在loss裡用了它們的平方。"
      ],
      "metadata": {
        "id": "3ztbsLXow0i4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. 簡單的訓練 loop\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "for step in range(1000):\n",
        "    optimizer.zero_grad()\n",
        "    loss, info = constraint_loss(model, N_samples)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if step % 100 == 0:\n",
        "        print(f\"step {step:4d}  loss = {loss.item():.4e}  \"\n",
        "              f\"mean_u = {info['mean_u']:.2e}, \"\n",
        "              f\"poincare_violation = {info['poincare_violation']:.2e}, \"\n",
        "              f\"sobolev_violation = {info['sobolev_violation']:.2e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBS3nboZtKjZ",
        "outputId": "16437290-f621-4949-ba1b-2f16c63afc0e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step    0  loss = 4.5381e-01  mean_u = 3.89e-01, poincare_violation = 3.89e-01, sobolev_violation = 3.89e-01\n",
            "step  100  loss = 8.4966e-05  mean_u = -1.36e-03, poincare_violation = 9.07e-04, sobolev_violation = 9.07e-03\n",
            "step  200  loss = 7.7598e-05  mean_u = -1.25e-05, poincare_violation = 0.00e+00, sobolev_violation = 8.81e-03\n",
            "step  300  loss = 7.1569e-05  mean_u = -1.64e-05, poincare_violation = 0.00e+00, sobolev_violation = 8.46e-03\n",
            "step  400  loss = 6.4438e-05  mean_u = 1.10e-05, poincare_violation = 0.00e+00, sobolev_violation = 8.03e-03\n",
            "step  500  loss = 5.6389e-05  mean_u = 2.37e-05, poincare_violation = 0.00e+00, sobolev_violation = 7.51e-03\n",
            "step  600  loss = 4.7623e-05  mean_u = -7.15e-06, poincare_violation = 0.00e+00, sobolev_violation = 6.90e-03\n",
            "step  700  loss = 3.8405e-05  mean_u = -7.71e-05, poincare_violation = 0.00e+00, sobolev_violation = 6.20e-03\n",
            "step  800  loss = 2.9172e-05  mean_u = 3.62e-05, poincare_violation = 0.00e+00, sobolev_violation = 5.40e-03\n",
            "step  900  loss = 2.0570e-05  mean_u = -4.23e-05, poincare_violation = 0.00e+00, sobolev_violation = 4.54e-03\n"
          ]
        }
      ]
    }
  ]
}